# ðŸš€ CI/CD Pipeline for Space Intelligence Platform
# Automated data updates, testing, and deployment

name: Space Intelligence CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run data updates every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Type of update to perform'
        required: true
        default: 'data'
        type: choice
        options:
        - data
        - full_deploy
        - test_only

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # ======================== DATA UPDATE JOB ========================
  update_data:
    name: ðŸŒŒ Update Real Space Data
    runs-on: ubuntu-latest
    if: github.event.schedule || github.event.inputs.update_type == 'data' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        
    - name: ðŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install requests pandas numpy pillow opencv-python
        
    - name: ðŸŒ Fetch NASA Solar Data
      run: |
        python -c "
        from real_data_sources import get_cached_solar_image
        import json
        import os
        from datetime import datetime
        
        print('ðŸŒž Fetching NASA Solar Data...')
        solar_data = get_cached_solar_image()
        
        # Create data directory
        os.makedirs('data/live', exist_ok=True)
        
        # Save metadata
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'NASA SDO',
            'status': 'success' if solar_data else 'failed',
            'image_available': bool(solar_data)
        }
        
        with open('data/live/solar_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('âœ… NASA Solar data updated')
        "
        
    - name: ðŸŒªï¸ Fetch NOAA Space Weather
      run: |
        python -c "
        from real_data_sources import get_cached_space_weather, get_cached_solar_flares
        import json
        import os
        from datetime import datetime
        
        print('ðŸŒªï¸ Fetching NOAA Space Weather...')
        weather_data = get_cached_space_weather()
        flare_data = get_cached_solar_flares()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'NOAA SWPC',
            'weather_status': 'success' if weather_data is not None else 'failed',
            'flare_status': 'success' if flare_data is not None else 'failed',
            'weather_records': len(weather_data) if weather_data is not None else 0,
            'flare_records': len(flare_data) if flare_data is not None else 0
        }
        
        with open('data/live/weather_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('âœ… NOAA Space Weather data updated')
        "
        
    - name: ðŸ  Fetch ISS Location
      run: |
        python -c "
        from real_data_sources import get_cached_iss_location
        import json
        import os
        from datetime import datetime
        
        print('ðŸ  Fetching ISS Location...')
        iss_data = get_cached_iss_location()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'ISS API',
            'status': 'success' if iss_data else 'failed',
            'location': iss_data if iss_data else None
        }
        
        with open('data/live/iss_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('âœ… ISS Location data updated')
        "
        
    - name: ðŸ’° Update Commodity Prices
      run: |
        python -c "
        from real_data_sources import get_cached_commodity_prices
        import json
        import os
        from datetime import datetime
        
        print('ðŸ’° Updating Commodity Prices...')
        commodity_data = get_cached_commodity_prices()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'Market APIs',
            'status': 'success' if commodity_data else 'failed',
            'commodities': list(commodity_data.keys()) if commodity_data else []
        }
        
        with open('data/live/commodity_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('âœ… Commodity prices updated')
        "
        
    - name: ðŸ“Š Generate Data Summary
      run: |
        python -c "
        import json
        import os
        from datetime import datetime
        from glob import glob
        
        print('ðŸ“Š Generating Data Summary...')
        
        # Read all metadata files
        summary = {
            'last_update': datetime.now().isoformat(),
            'sources': {}
        }
        
        metadata_files = glob('data/live/*_metadata.json')
        for file in metadata_files:
            with open(file, 'r') as f:
                data = json.load(f)
                source_name = os.path.basename(file).replace('_metadata.json', '')
                summary['sources'][source_name] = data
        
        # Save summary
        with open('data/live/data_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
            
        print('âœ… Data summary generated')
        print('ðŸ“ˆ Summary:', json.dumps(summary, indent=2))
        "
        
    - name: ðŸ’¾ Commit updated data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/live/
        if git diff --staged --quiet; then
          echo "No data changes to commit"
        else
          git commit -m "ðŸ¤– Auto-update: Live space data $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          git push
          echo "âœ… Data updated and pushed to repository"
        fi

  # ======================== TESTING JOB ========================
  test:
    name: ðŸ§ª Run Tests
    runs-on: ubuntu-latest
    needs: [update_data]
    if: always()
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      with:
        ref: ${{ github.ref }}
        
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov streamlit
        
    - name: ðŸ” Lint code
      run: |
        pip install flake8
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        
    - name: ðŸ§ª Test data sources
      run: |
        python verify_data_sources.py
        
    - name: ðŸš€ Test Streamlit app
      run: |
        timeout 30s streamlit run main.py --server.headless true --server.port 8501 &
        sleep 10
        curl -f http://localhost:8501 || exit 1
        pkill -f streamlit
        echo "âœ… Streamlit app test passed"

  # ======================== DEPLOYMENT JOB ========================
  deploy:
    name: ðŸš€ Deploy to Production
    runs-on: ubuntu-latest
    needs: [test]
    if: github.ref == 'refs/heads/main' && (github.event.inputs.update_type == 'full_deploy' || github.event_name == 'push')
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: ðŸ”§ Build production package
      run: |
        mkdir -p dist/
        cp -r *.py requirements*.txt data/ docs/ dist/
        echo "âœ… Production package built"
        
    - name: ðŸ“Š Generate deployment info
      run: |
        cat > dist/deployment_info.json << EOF
        {
          "version": "3.0.$(date +%Y%m%d%H%M%S)",
          "commit": "${{ github.sha }}",
          "branch": "${{ github.ref_name }}",
          "deploy_time": "$(date -u '+%Y-%m-%d %H:%M:%S UTC')",
          "environment": "production"
        }
        EOF
        
    - name: ðŸŒ Deploy to Streamlit Cloud (Mock)
      run: |
        echo "ðŸš€ Deploying to production..."
        echo "âœ… Deployment URL: https://space-intelligence-platform.streamlit.app"
        echo "ðŸŽ¯ Status: Production Ready"
        
    # Add real deployment steps here based on your hosting platform
    # Examples:
    # - Deploy to Heroku
    # - Deploy to AWS/GCP/Azure
    # - Deploy to Streamlit Cloud
    # - Deploy to Docker registry

  # ======================== NOTIFICATION JOB ========================
  notify:
    name: ðŸ“¢ Send Notifications
    runs-on: ubuntu-latest
    needs: [update_data, test, deploy]
    if: always()
    
    steps:
    - name: ðŸ“Š Check job results
      run: |
        echo "ðŸ“Š Pipeline Results:"
        echo "Data Update: ${{ needs.update_data.result }}"
        echo "Tests: ${{ needs.test.result }}"
        echo "Deployment: ${{ needs.deploy.result }}"
        
        if [[ "${{ needs.update_data.result }}" == "success" && "${{ needs.test.result }}" == "success" ]]; then
          echo "âœ… Pipeline completed successfully!"
          echo "ðŸš€ Space Intelligence Platform is operational"
        else
          echo "âš ï¸ Pipeline had some issues"
          exit 1
        fi

  # ======================== HEALTH CHECK ========================
  health_check:
    name: ðŸ¥ System Health Check
    runs-on: ubuntu-latest
    needs: [notify]
    if: always()
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ¥ Run health checks
      run: |
        echo "ðŸ¥ Running system health checks..."
        
        # Check if main files exist
        required_files=(
          "main.py"
          "real_data_sources.py" 
          "core_utils.py"
          "requirements.txt"
        )
        
        for file in "${required_files[@]}"; do
          if [[ -f "$file" ]]; then
            echo "âœ… $file exists"
          else
            echo "âŒ $file missing"
            exit 1
          fi
        done
        
        echo "âœ… All system health checks passed!"