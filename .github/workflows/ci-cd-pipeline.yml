# 🚀 CI/CD Pipeline for Space Intelligence Platform
# Automated data updates, testing, and deployment

name: Space Intelligence CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run data updates every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Type of update to perform'
        required: true
        default: 'data'
        type: choice
        options:
        - data
        - full_deploy
        - test_only

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # ======================== DATA UPDATE JOB ========================
  update_data:
    name: 🌌 Update Real Space Data
    runs-on: ubuntu-latest
    if: github.event.schedule || github.event.inputs.update_type == 'data' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: 📦 Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        
    - name: 🔧 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install requests pandas numpy pillow opencv-python
        
    - name: 🌍 Fetch NASA Solar Data
      run: |
        python -c "
        from real_data_sources import get_cached_solar_image
        import json
        import os
        from datetime import datetime
        
        print('🌞 Fetching NASA Solar Data...')
        solar_data = get_cached_solar_image()
        
        # Create data directory
        os.makedirs('data/live', exist_ok=True)
        
        # Save metadata
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'NASA SDO',
            'status': 'success' if solar_data else 'failed',
            'image_available': bool(solar_data)
        }
        
        with open('data/live/solar_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('✅ NASA Solar data updated')
        "
        
    - name: 🌪️ Fetch NOAA Space Weather
      run: |
        python -c "
        from real_data_sources import get_cached_space_weather, get_cached_solar_flares
        import json
        import os
        from datetime import datetime
        
        print('🌪️ Fetching NOAA Space Weather...')
        weather_data = get_cached_space_weather()
        flare_data = get_cached_solar_flares()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'NOAA SWPC',
            'weather_status': 'success' if weather_data is not None else 'failed',
            'flare_status': 'success' if flare_data is not None else 'failed',
            'weather_records': len(weather_data) if weather_data is not None else 0,
            'flare_records': len(flare_data) if flare_data is not None else 0
        }
        
        with open('data/live/weather_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('✅ NOAA Space Weather data updated')
        "
        
    - name: 🏠 Fetch ISS Location
      run: |
        python -c "
        from real_data_sources import get_cached_iss_location
        import json
        import os
        from datetime import datetime
        
        print('🏠 Fetching ISS Location...')
        iss_data = get_cached_iss_location()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'ISS API',
            'status': 'success' if iss_data else 'failed',
            'location': iss_data if iss_data else None
        }
        
        with open('data/live/iss_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('✅ ISS Location data updated')
        "
        
    - name: 💰 Update Commodity Prices
      run: |
        python -c "
        from real_data_sources import get_cached_commodity_prices
        import json
        import os
        from datetime import datetime
        
        print('💰 Updating Commodity Prices...')
        commodity_data = get_cached_commodity_prices()
        
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'source': 'Market APIs',
            'status': 'success' if commodity_data else 'failed',
            'commodities': list(commodity_data.keys()) if commodity_data else []
        }
        
        with open('data/live/commodity_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print('✅ Commodity prices updated')
        "
        
    - name: 📊 Generate Data Summary
      run: |
        python -c "
        import json
        import os
        from datetime import datetime
        from glob import glob
        
        print('📊 Generating Data Summary...')
        
        # Read all metadata files
        summary = {
            'last_update': datetime.now().isoformat(),
            'sources': {}
        }
        
        metadata_files = glob('data/live/*_metadata.json')
        for file in metadata_files:
            with open(file, 'r') as f:
                data = json.load(f)
                source_name = os.path.basename(file).replace('_metadata.json', '')
                summary['sources'][source_name] = data
        
        # Save summary
        with open('data/live/data_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
            
        print('✅ Data summary generated')
        print('📈 Summary:', json.dumps(summary, indent=2))
        "
        
    - name: 💾 Commit updated data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/live/
        if git diff --staged --quiet; then
          echo "No data changes to commit"
        else
          git commit -m "🤖 Auto-update: Live space data $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          git push
          echo "✅ Data updated and pushed to repository"
        fi

  # ======================== TESTING JOB ========================
  test:
    name: 🧪 Run Tests
    runs-on: ubuntu-latest
    needs: [update_data]
    if: always()
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      with:
        ref: ${{ github.ref }}
        
    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov streamlit
        
    - name: 🔍 Lint code
      run: |
        pip install flake8
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        
    - name: 🧪 Test data sources
      run: |
        python verify_data_sources.py
        
    - name: 🚀 Test Streamlit app
      run: |
        timeout 30s streamlit run main.py --server.headless true --server.port 8501 &
        sleep 10
        curl -f http://localhost:8501 || exit 1
        pkill -f streamlit
        echo "✅ Streamlit app test passed"

  # ======================== DEPLOYMENT JOB ========================
  deploy:
    name: 🚀 Deploy to Production
    runs-on: ubuntu-latest
    needs: [test]
    if: github.ref == 'refs/heads/main' && (github.event.inputs.update_type == 'full_deploy' || github.event_name == 'push')
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: 📦 Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 🔧 Build production package
      run: |
        mkdir -p dist/
        cp -r *.py requirements*.txt data/ docs/ dist/
        echo "✅ Production package built"
        
    - name: 📊 Generate deployment info
      run: |
        cat > dist/deployment_info.json << EOF
        {
          "version": "3.0.$(date +%Y%m%d%H%M%S)",
          "commit": "${{ github.sha }}",
          "branch": "${{ github.ref_name }}",
          "deploy_time": "$(date -u '+%Y-%m-%d %H:%M:%S UTC')",
          "environment": "production"
        }
        EOF
        
    - name: 🌐 Deploy to Streamlit Cloud (Mock)
      run: |
        echo "🚀 Deploying to production..."
        echo "✅ Deployment URL: https://space-intelligence-platform.streamlit.app"
        echo "🎯 Status: Production Ready"
        
    # Add real deployment steps here based on your hosting platform
    # Examples:
    # - Deploy to Heroku
    # - Deploy to AWS/GCP/Azure
    # - Deploy to Streamlit Cloud
    # - Deploy to Docker registry

  # ======================== NOTIFICATION JOB ========================
  notify:
    name: 📢 Send Notifications
    runs-on: ubuntu-latest
    needs: [update_data, test, deploy]
    if: always()
    
    steps:
    - name: 📊 Check job results
      run: |
        echo "📊 Pipeline Results:"
        echo "Data Update: ${{ needs.update_data.result }}"
        echo "Tests: ${{ needs.test.result }}"
        echo "Deployment: ${{ needs.deploy.result }}"
        
        if [[ "${{ needs.update_data.result }}" == "success" && "${{ needs.test.result }}" == "success" ]]; then
          echo "✅ Pipeline completed successfully!"
          echo "🚀 Space Intelligence Platform is operational"
        else
          echo "⚠️ Pipeline had some issues"
          exit 1
        fi

  # ======================== HEALTH CHECK ========================
  health_check:
    name: 🏥 System Health Check
    runs-on: ubuntu-latest
    needs: [notify]
    if: always()
    
    steps:
    - name: 📥 Checkout code
      uses: actions/checkout@v4
      
    - name: 🏥 Run health checks
      run: |
        echo "🏥 Running system health checks..."
        
        # Check if main files exist
        required_files=(
          "main.py"
          "real_data_sources.py" 
          "core_utils.py"
          "requirements.txt"
        )
        
        for file in "${required_files[@]}"; do
          if [[ -f "$file" ]]; then
            echo "✅ $file exists"
          else
            echo "❌ $file missing"
            exit 1
          fi
        done
        
        echo "✅ All system health checks passed!"